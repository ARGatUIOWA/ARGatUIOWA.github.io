<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://argatuiowa.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://argatuiowa.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-09-07T16:06:50+00:00</updated><id>https://argatuiowa.github.io/feed.xml</id><title type="html">Algorithms Reading Group</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Hongyan Ji presents “Solving Sequential Greedy Problems Distributedly with Sub-Logarithmic Energy Cost”</title><link href="https://argatuiowa.github.io/blog/2025/Hongyan/" rel="alternate" type="text/html" title="Hongyan Ji presents “Solving Sequential Greedy Problems Distributedly with Sub-Logarithmic Energy Cost”"/><published>2025-09-11T06:00:00+00:00</published><updated>2025-09-11T06:00:00+00:00</updated><id>https://argatuiowa.github.io/blog/2025/Hongyan</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2025/Hongyan/"><![CDATA[<p><strong>Abstract</strong>: We study the awake complexity of graph problems that belong to the class O-LOCAL, which includes a subset of problems solvable by sequential greedy algorithms, such as \((\Delta+1)\)-coloring and maximal independent set. It is known from previous work that, in \(n\)-node graphs of maximum degree \(\Delta\), any problem in the class O-LOCAL can be solved by a deterministic distributed algorithm with awake complexity \(O(\log\Delta+\log^\star n)\). In this paper, we show that any problem belonging to the class O-LOCAL can be solved by a deterministic distributed algorithm with awake complexity \(O(\sqrt{\log n}\cdot\log^\star n)\). This leads to a polynomial improvement over the state of the art when \(\Delta\gg 2^{\sqrt{\log n}}\), e.g., \(\Delta=n^\epsilon\) for some arbitrarily small \(\epsilon&gt;0\). The key ingredient for achieving our results is the computation of a network decomposition, that uses a small-enough number of colors, in sub-logarithmic time in the Sleeping model, which can be of independent interest.</p> <p><a href="https://arxiv.org/abs/2410.20499">Solving Sequential Greedy Problems Distributedly with Sub-Logarithmic Energy Cost</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Abstract: We study the awake complexity of graph problems that belong to the class O-LOCAL, which includes a subset of problems solvable by sequential greedy algorithms, such as \((\Delta+1)\)-coloring and maximal independent set. It is known from previous work that, in \(n\)-node graphs of maximum degree \(\Delta\), any problem in the class O-LOCAL can be solved by a deterministic distributed algorithm with awake complexity \(O(\log\Delta+\log^\star n)\). In this paper, we show that any problem belonging to the class O-LOCAL can be solved by a deterministic distributed algorithm with awake complexity \(O(\sqrt{\log n}\cdot\log^\star n)\). This leads to a polynomial improvement over the state of the art when \(\Delta\gg 2^{\sqrt{\log n}}\), e.g., \(\Delta=n^\epsilon\) for some arbitrarily small \(\epsilon&gt;0\). The key ingredient for achieving our results is the computation of a network decomposition, that uses a small-enough number of colors, in sub-logarithmic time in the Sleeping model, which can be of independent interest.]]></summary></entry><entry><title type="html">Joshua Sobel presents “Work-Efficient Parallel Counting via Sampling”</title><link href="https://argatuiowa.github.io/blog/2025/Josh/" rel="alternate" type="text/html" title="Joshua Sobel presents “Work-Efficient Parallel Counting via Sampling”"/><published>2025-09-04T06:00:00+00:00</published><updated>2025-09-04T06:00:00+00:00</updated><id>https://argatuiowa.github.io/blog/2025/Josh</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2025/Josh/"><![CDATA[<p><strong>Abstract</strong>: A canonical approach to approximating the partition function of a Gibbs distribution via sampling is simulated annealing. This method has led to efficient reductions from counting to sampling, including: \(\bullet\) classic non-adaptive (parallel) algorithms with sub-optimal cost (Dyer-Frieze-Kannan ‘89; Bezáková-Štefankovič-Vazirani-Vigoda ‘08); \(\bullet\) adaptive (sequential) algorithms with near-optimal cost (Štefankovič-Vempala-Vigoda ‘09; Huber ‘15; Kolmogorov ‘18; Harris-Kolmogorov ‘24). We present an algorithm that achieves both near-optimal total work and efficient parallelism, providing a reduction from counting to sampling with logarithmic depth and near-optimal work. As consequences, we obtain work-efficient parallel counting algorithms for several important models, including the hardcore and Ising models within the uniqueness regime.</p> <p><a href="https://arxiv.org/abs/2408.09719">Work-Efficient Parallel Counting via Sampling</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Abstract: A canonical approach to approximating the partition function of a Gibbs distribution via sampling is simulated annealing. This method has led to efficient reductions from counting to sampling, including: \(\bullet\) classic non-adaptive (parallel) algorithms with sub-optimal cost (Dyer-Frieze-Kannan ‘89; Bezáková-Štefankovič-Vazirani-Vigoda ‘08); \(\bullet\) adaptive (sequential) algorithms with near-optimal cost (Štefankovič-Vempala-Vigoda ‘09; Huber ‘15; Kolmogorov ‘18; Harris-Kolmogorov ‘24). We present an algorithm that achieves both near-optimal total work and efficient parallelism, providing a reduction from counting to sampling with logarithmic depth and near-optimal work. As consequences, we obtain work-efficient parallel counting algorithms for several important models, including the hardcore and Ising models within the uniqueness regime.]]></summary></entry><entry><title type="html">Yongjian Zhong presents “Can Q-learning be improved with advice?”</title><link href="https://argatuiowa.github.io/blog/2023/Yongjian/" rel="alternate" type="text/html" title="Yongjian Zhong presents “Can Q-learning be improved with advice?”"/><published>2023-11-28T08:30:00+00:00</published><updated>2023-11-28T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Yongjian</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Yongjian/"><![CDATA[<p><strong>Abstract</strong>: Despite rapid progress in theoretical reinforcement learning (RL) over the last few years, most of the known guarantees are worst-case in nature, failing to take advantage of structure that may be known a priori about a given RL problem at hand. In this paper we address the question of whether worst-case lower bounds for regret in online learning of Markov decision processes (MDPs) can be circumvented when information about the MDP, in the form of predictions about its optimal Q-value function, is given to the algorithm. We show that when the predictions about the optimal Q-value function satisfy a reasonably weak condition we call distillation, then we can improve regret bounds by replacing the set of state-action pairs with the set of state-action pairs on which the predictions are grossly inaccurate. This improvement holds for both uniform regret bounds and gap-based ones. Further, we are able to achieve this property with an algorithm that achieves sublinear regret when given arbitrary predictions (i.e., even those which are not a distillation). Our work extends a recent line of work on algorithms with predictions, which has typically focused on simple online problems such as caching and scheduling, to the more complex and general problem of reinforcement learning.</p> <p><a href="https://arxiv.org/pdf/2110.13052.pdf">Can Q-learning be improved with advice?</a></p>]]></content><author><name></name></author><category term="Q-learning"/><summary type="html"><![CDATA[Abstract: Despite rapid progress in theoretical reinforcement learning (RL) over the last few years, most of the known guarantees are worst-case in nature, failing to take advantage of structure that may be known a priori about a given RL problem at hand. In this paper we address the question of whether worst-case lower bounds for regret in online learning of Markov decision processes (MDPs) can be circumvented when information about the MDP, in the form of predictions about its optimal Q-value function, is given to the algorithm. We show that when the predictions about the optimal Q-value function satisfy a reasonably weak condition we call distillation, then we can improve regret bounds by replacing the set of state-action pairs with the set of state-action pairs on which the predictions are grossly inaccurate. This improvement holds for both uniform regret bounds and gap-based ones. Further, we are able to achieve this property with an algorithm that achieves sublinear regret when given arbitrary predictions (i.e., even those which are not a distillation). Our work extends a recent line of work on algorithms with predictions, which has typically focused on simple online problems such as caching and scheduling, to the more complex and general problem of reinforcement learning.]]></summary></entry><entry><title type="html">Sriram Pemmaraju presents “The primal-dual method for learning augmented algorithms”</title><link href="https://argatuiowa.github.io/blog/2023/Sriram/" rel="alternate" type="text/html" title="Sriram Pemmaraju presents “The primal-dual method for learning augmented algorithms”"/><published>2023-11-07T08:30:00+00:00</published><updated>2023-11-07T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Sriram</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Sriram/"><![CDATA[<p><strong>Abstract</strong>: The extension of classical online algorithms when provided with predictions is a new and active research area. In this paper, we extend the primal-dual method for online algorithms in order to incorporate predictions that advise the online algorithm about the next action to take. We use this framework to obtain novel algorithms for a variety of online covering problems. We compare our algorithms to the cost of the true and predicted offline optimal solutions and show that these algorithms outperform any online algorithm when the prediction is accurate while maintaining good guarantees when the prediction is misleading.</p> <p><a href="https://arxiv.org/pdf/2010.11632.pdf">The primal-dual method for learning augmented algorithms</a></p>]]></content><author><name></name></author><category term="primal-dual"/><summary type="html"><![CDATA[Abstract: The extension of classical online algorithms when provided with predictions is a new and active research area. In this paper, we extend the primal-dual method for online algorithms in order to incorporate predictions that advise the online algorithm about the next action to take. We use this framework to obtain novel algorithms for a variety of online covering problems. We compare our algorithms to the cost of the true and predicted offline optimal solutions and show that these algorithms outperform any online algorithm when the prediction is accurate while maintaining good guarantees when the prediction is misleading.]]></summary></entry><entry><title type="html">Mehrdad Moharrami presents “A Universal Randomized Packet Scheduling Algorithm”</title><link href="https://argatuiowa.github.io/blog/2023/Mehrdad/" rel="alternate" type="text/html" title="Mehrdad Moharrami presents “A Universal Randomized Packet Scheduling Algorithm”"/><published>2023-10-31T08:30:00+00:00</published><updated>2023-10-31T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Mehrdad</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Mehrdad/"><![CDATA[<p><strong>Abstract</strong>: We give a memoryless scale-invariant randomized algorithm REMIX for Packet Scheduling that is \(\epsilon/(\epsilon−1)\)-competitive against an adaptive adversary. REMIX unifies most of previously known randomized algorithms, and its general analysis yields improved performance guarantees for several restricted variants, including the s-bounded instances. In particular, REMIX attains the optimum competitive ratio of \(4/3\) on 2-bounded instances.</p> <p>Our results are applicable to a more general problem, called Item Collection, in which only the relative order between packets’ deadlines is known. REMIX is the optimal memoryless randomized algorithm against adaptive adversary for that problem.</p> <p><a href="https://link.springer.com/article/10.1007/s00453-012-9700-0">A Universal Randomized Packet Scheduling Algorithm</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Abstract: We give a memoryless scale-invariant randomized algorithm REMIX for Packet Scheduling that is \(\epsilon/(\epsilon−1)\)-competitive against an adaptive adversary. REMIX unifies most of previously known randomized algorithms, and its general analysis yields improved performance guarantees for several restricted variants, including the s-bounded instances. In particular, REMIX attains the optimum competitive ratio of \(4/3\) on 2-bounded instances.]]></summary></entry><entry><title type="html">Joshua Sobel presents “Graph Searching with Predictions”</title><link href="https://argatuiowa.github.io/blog/2023/Josh/" rel="alternate" type="text/html" title="Joshua Sobel presents “Graph Searching with Predictions”"/><published>2023-10-17T08:30:00+00:00</published><updated>2023-10-17T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Josh</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Josh/"><![CDATA[<p><strong>Abstract</strong>: Consider an agent exploring an unknown graph in search of some goal state. As it walks around the graph, it learns the nodes and their neighbors. The agent only knows where the goal state is when it reaches it. How do we reach this goal while moving only a small distance? This problem seems hopeless, even on trees of bounded degree, unless we give the agent some help. This setting with “help” often arises in exploring large search spaces (e.g., huge game trees) where we assume access to some score/quality function for each node, which we use to guide us towards the goal. In our case, we assume the help comes in the form of distance predictions: each node v provides a prediction $f(v)$ of its distance to the goal vertex. Naturally if these predictions are correct, we can reach the goal along a shortest path. What if the predictions are unreliable and some of them are erroneous? Can we get an algorithm whose performance relates to the error of the predictions? In this work, we consider the problem on trees and give deterministic algorithms whose total movement cost is only $O(OPT +\Delta\cdot ERR)$, where $OPT$ is the distance from the start to the goal vertex, $\Delta$ the maximum degree, and the $ERR$ is the total number of vertices whose predictions are erroneous. We show this guarantee is optimal. We then consider a “planning” version of the problem where the graph and predictions are known at the beginning, so the agent can use this global information to devise a search strategy of low cost. For this planning version, we go beyond trees and give an algorithms which gets good performance on (weighted) graphs with bounded doubling dimension.</p> <p><a href="https://arxiv.org/pdf/2212.14220.pdf">Graph Searching with Predictions</a></p>]]></content><author><name></name></author><category term="exploration"/><category term="planning"/><summary type="html"><![CDATA[Abstract: Consider an agent exploring an unknown graph in search of some goal state. As it walks around the graph, it learns the nodes and their neighbors. The agent only knows where the goal state is when it reaches it. How do we reach this goal while moving only a small distance? This problem seems hopeless, even on trees of bounded degree, unless we give the agent some help. This setting with “help” often arises in exploring large search spaces (e.g., huge game trees) where we assume access to some score/quality function for each node, which we use to guide us towards the goal. In our case, we assume the help comes in the form of distance predictions: each node v provides a prediction $f(v)$ of its distance to the goal vertex. Naturally if these predictions are correct, we can reach the goal along a shortest path. What if the predictions are unreliable and some of them are erroneous? Can we get an algorithm whose performance relates to the error of the predictions? In this work, we consider the problem on trees and give deterministic algorithms whose total movement cost is only $O(OPT +\Delta\cdot ERR)$, where $OPT$ is the distance from the start to the goal vertex, $\Delta$ the maximum degree, and the $ERR$ is the total number of vertices whose predictions are erroneous. We show this guarantee is optimal. We then consider a “planning” version of the problem where the graph and predictions are known at the beginning, so the agent can use this global information to devise a search strategy of low cost. For this planning version, we go beyond trees and give an algorithms which gets good performance on (weighted) graphs with bounded doubling dimension.]]></summary></entry><entry><title type="html">Jeffrey S Keithley presents “Proportionally Fair Online Allocation of Public Goods with Predictions”</title><link href="https://argatuiowa.github.io/blog/2023/Jeff/" rel="alternate" type="text/html" title="Jeffrey S Keithley presents “Proportionally Fair Online Allocation of Public Goods with Predictions”"/><published>2023-10-10T08:30:00+00:00</published><updated>2023-10-10T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Jeff</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Jeff/"><![CDATA[<p><strong>Abstract</strong>: We design online algorithms for the fair allocation of public goods to a set of N agents over a sequence of T rounds and focus on improving their performance using predictions. In the basic model, a public good arrives in each round, the algorithm learns every agent’s value for the good, and must irrevocably decide the amount of investment in the good without exceeding a total budget of B across all rounds. The algorithm can utilize (potentially inaccurate) predictions of each agent’s total value for all the goods to arrive. We measure the performance of the algorithm using a proportional fairness objective, which informally demands that every group of agents be rewarded in proportion to its size and the cohesiveness of its preferences. In the special case of binary agent preferences and a unit budget, we show that $O(\log N)$ proportional fairness can be achieved without using any predictions, and that this is optimal even if perfectly accurate predictions were available. However, for general preferences and budget no algorithm can achieve better than $\Theta(T/B)$ proportional fairness without predictions. We show that algorithms with (reasonably accurate) predictions can do much better, achieving $\Theta(\log(T/B))$ proportional fairness. We also extend this result to a general model in which a batch of L public goods arrive in each round and achieve $O(\log(min(N,L)\cdot T/B))$ proportional fairness. Our exact bounds are parametrized as a function of the error in the predictions and the performance degrades gracefully with increasing errors.</p> <p><a href="https://arxiv.org/abs/2209.15305">Proportionally Fair Online Allocation of Public Goods with Predictions</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Abstract: We design online algorithms for the fair allocation of public goods to a set of N agents over a sequence of T rounds and focus on improving their performance using predictions. In the basic model, a public good arrives in each round, the algorithm learns every agent’s value for the good, and must irrevocably decide the amount of investment in the good without exceeding a total budget of B across all rounds. The algorithm can utilize (potentially inaccurate) predictions of each agent’s total value for all the goods to arrive. We measure the performance of the algorithm using a proportional fairness objective, which informally demands that every group of agents be rewarded in proportion to its size and the cohesiveness of its preferences. In the special case of binary agent preferences and a unit budget, we show that $O(\log N)$ proportional fairness can be achieved without using any predictions, and that this is optimal even if perfectly accurate predictions were available. However, for general preferences and budget no algorithm can achieve better than $\Theta(T/B)$ proportional fairness without predictions. We show that algorithms with (reasonably accurate) predictions can do much better, achieving $\Theta(\log(T/B))$ proportional fairness. We also extend this result to a general model in which a batch of L public goods arrive in each round and achieve $O(\log(min(N,L)\cdot T/B))$ proportional fairness. Our exact bounds are parametrized as a function of the error in the predictions and the performance degrades gracefully with increasing errors.]]></summary></entry><entry><title type="html">Hongyan Ji presents “Learning-Augmented Algorithms for Online Steiner Tree”</title><link href="https://argatuiowa.github.io/blog/2023/Hongyan/" rel="alternate" type="text/html" title="Hongyan Ji presents “Learning-Augmented Algorithms for Online Steiner Tree”"/><published>2023-10-03T08:30:00+00:00</published><updated>2023-10-03T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Hongyan</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Hongyan/"><![CDATA[<p><strong>Abstract</strong>: This paper considers the recently popular beyond-worst-case algorithm analysis model which integrates machine-learned predictions with online algorithm design. We consider the on- line Steiner tree problem in this model for both directed and undirected graphs. Steiner tree is known to have strong lower bounds in the online setting and any algorithm’s worst-case guarantee is far from desirable. This paper considers algorithms that predict which terminal arrives online. The predictions may be incorrect and the al- gorithms’ performance is parameterized by the number of in- correctly predicted terminals. These guarantees ensure that algorithms break through the online lower bounds with good predictions and the competitive ratio gracefully degrades as the prediction error grows. We then observe that the theory is predictive of what will occur empirically. We show on graphs where terminals are drawn from a distribution, the new on- line algorithms have strong performance even with modestly correct predictions.</p> <p><a href="https://arxiv.org/pdf/2112.05353.pdf">Learning-Augmented Algorithms for Online Steiner Tree</a></p>]]></content><author><name></name></author><category term="online"/><category term="steiner-tree"/><summary type="html"><![CDATA[Abstract: This paper considers the recently popular beyond-worst-case algorithm analysis model which integrates machine-learned predictions with online algorithm design. We consider the on- line Steiner tree problem in this model for both directed and undirected graphs. Steiner tree is known to have strong lower bounds in the online setting and any algorithm’s worst-case guarantee is far from desirable. This paper considers algorithms that predict which terminal arrives online. The predictions may be incorrect and the al- gorithms’ performance is parameterized by the number of in- correctly predicted terminals. These guarantees ensure that algorithms break through the online lower bounds with good predictions and the competitive ratio gracefully degrades as the prediction error grows. We then observe that the theory is predictive of what will occur empirically. We show on graphs where terminals are drawn from a distribution, the new on- line algorithms have strong performance even with modestly correct predictions.]]></summary></entry><entry><title type="html">Sourya Roy presents “(Learned) Frequency Estimation Algorithms under Zipfian Distribution”</title><link href="https://argatuiowa.github.io/blog/2023/Sourya/" rel="alternate" type="text/html" title="Sourya Roy presents “(Learned) Frequency Estimation Algorithms under Zipfian Distribution”"/><published>2023-09-26T08:30:00+00:00</published><updated>2023-09-26T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Sourya</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Sourya/"><![CDATA[<p><strong>Abstract</strong>: The frequencies of the elements in a data stream are an important statistical measure and the task of estimating them arises in many applications within data analysis and machine learning. Two of the most popular algorithms for this problem, Count-Min and Count-Sketch, are widely used in practice. In a recent work [Hsu et al., ICLR’19], it was shown empirically that augmenting Count- Min and Count-Sketch with a machine learning algorithm leads to a significant reduction of the estimation error. The experiments were complemented with an analysis of the expected error incurred by Count-Min (both the standard and the augmented version) when the input frequencies follow a Zipfian distribution. Although the authors established that the learned version of Count-Min has lower estimation error than its standard counterpart, their analysis of the standard Count-Min algorithm was not tight. Moreover, they provided no similar analysis for Count-Sketch. In this paper we resolve these problems. First, we provide a simple tight analysis of the expected error incurred by Count-Min. Second, we provide the first error bounds for both the standard and the augmented version of Count-Sketch. These bounds are nearly tight and again demonstrate an improved performance of the learned version of Count-Sketch. In addition to demonstrating tight gaps between the aforementioned algorithms, we believe that our bounds for the standard versions of Count-Min and Count-Sketch are of independent interest. In particular, it is a typical practice to set the number of hash functions in those algorithms to $\theta(\log n)$. In contrast, our results show that to minimize the expected error, the number of hash functions should be a constant, strictly greater than 1.</p> <p><a href="https://arxiv.org/pdf/1908.05198.pdf">(Learned) Frequency Estimation Algorithms under Zipfian Distribution</a></p>]]></content><author><name></name></author><category term="streaming-algorithms"/><summary type="html"><![CDATA[Abstract: The frequencies of the elements in a data stream are an important statistical measure and the task of estimating them arises in many applications within data analysis and machine learning. Two of the most popular algorithms for this problem, Count-Min and Count-Sketch, are widely used in practice. In a recent work [Hsu et al., ICLR’19], it was shown empirically that augmenting Count- Min and Count-Sketch with a machine learning algorithm leads to a significant reduction of the estimation error. The experiments were complemented with an analysis of the expected error incurred by Count-Min (both the standard and the augmented version) when the input frequencies follow a Zipfian distribution. Although the authors established that the learned version of Count-Min has lower estimation error than its standard counterpart, their analysis of the standard Count-Min algorithm was not tight. Moreover, they provided no similar analysis for Count-Sketch. In this paper we resolve these problems. First, we provide a simple tight analysis of the expected error incurred by Count-Min. Second, we provide the first error bounds for both the standard and the augmented version of Count-Sketch. These bounds are nearly tight and again demonstrate an improved performance of the learned version of Count-Sketch. In addition to demonstrating tight gaps between the aforementioned algorithms, we believe that our bounds for the standard versions of Count-Min and Count-Sketch are of independent interest. In particular, it is a typical practice to set the number of hash functions in those algorithms to $\theta(\log n)$. In contrast, our results show that to minimize the expected error, the number of hash functions should be a constant, strictly greater than 1.]]></summary></entry><entry><title type="html">Xiang Liu presents “Machine Learning Advised Ski Rental Problem with a Discount”</title><link href="https://argatuiowa.github.io/blog/2023/Xiang/" rel="alternate" type="text/html" title="Xiang Liu presents “Machine Learning Advised Ski Rental Problem with a Discount”"/><published>2023-09-19T08:30:00+00:00</published><updated>2023-09-19T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Xiang</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Xiang/"><![CDATA[<p><strong>Abstract</strong>: Traditional online algorithms are designed to make decisions online in the face of uncertainty to perform well in comparison with the optimal offline algorithm for the worst-case inputs. On the other hand, machine learning algorithms try to extrapolate the pattern from the past inputs to predict the future and take decisions online on basis of the predictions to perform well for the average-case inputs. There have been recent studies to augment traditional online algorithms with machine learning oracles to get better performance for all the possible inputs. The machine learning augmented online algorithms perform provably better than the traditional online algorithms when the error of the machine learning oracle is low for the worst-case inputs and all other average-case inputs. In this paper, we integrate the advantages of the traditional online algorithms and the machine learning algorithms in the context of a novel variant of the ski rental problem. Firstly, we propose the ski rental problem with a discount: in this problem, the rent of the ski, instead of being fixed over time, varies as a function of time. Secondly, we discuss the design and performance evaluation of the online algorithms with machine learning advice to solve the ski rental problem with a discount. Finally, we extend this study to the situation where multiple independent machine learning advice is available. This algorithm design framework motivates to redesign of several online algorithms by augmenting them with one or more machine learning oracles to improve the performance.</p> <p><a href="https://dl.acm.org/doi/abs/10.1007/978-3-030-96731-4_18">Machine Learning Advised Ski Rental Problem with a Discount</a></p>]]></content><author><name></name></author><category term="online"/><category term="ski-rental"/><summary type="html"><![CDATA[Abstract: Traditional online algorithms are designed to make decisions online in the face of uncertainty to perform well in comparison with the optimal offline algorithm for the worst-case inputs. On the other hand, machine learning algorithms try to extrapolate the pattern from the past inputs to predict the future and take decisions online on basis of the predictions to perform well for the average-case inputs. There have been recent studies to augment traditional online algorithms with machine learning oracles to get better performance for all the possible inputs. The machine learning augmented online algorithms perform provably better than the traditional online algorithms when the error of the machine learning oracle is low for the worst-case inputs and all other average-case inputs. In this paper, we integrate the advantages of the traditional online algorithms and the machine learning algorithms in the context of a novel variant of the ski rental problem. Firstly, we propose the ski rental problem with a discount: in this problem, the rent of the ski, instead of being fixed over time, varies as a function of time. Secondly, we discuss the design and performance evaluation of the online algorithms with machine learning advice to solve the ski rental problem with a discount. Finally, we extend this study to the situation where multiple independent machine learning advice is available. This algorithm design framework motivates to redesign of several online algorithms by augmenting them with one or more machine learning oracles to improve the performance.]]></summary></entry></feed>